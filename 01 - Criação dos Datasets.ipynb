{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importações",
   "id": "9cc7a4c844a5230e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-16T23:48:20.071335Z",
     "start_time": "2025-01-16T23:48:19.112006Z"
    }
   },
   "source": [
    "from calendar import month\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import calendar\n",
    "import locale\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "\n",
    "from jinja2 import Undefined\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'pt_BR.UTF-8')\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt_BR.UTF-8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Carregar datasets básicos",
   "id": "72f220b34ac4c7bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T23:48:20.268155Z",
     "start_time": "2025-01-16T23:48:20.178509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "consumo = pd.read_csv('./dados/consumo.csv', sep=\";\", header=0)\n",
    "consumo[\"DATA INICIO\"] = pd.to_datetime(consumo['DATA INICIO'], format='%d/%m/%Y')\n",
    "consumo[\"DATA FIM\"] = pd.to_datetime(consumo['DATA FIM'], format='%d/%m/%Y')\n",
    "feriados = pd.read_csv('dados/calendarios.csv', sep=\";\", header=0)\n",
    "cursos_sup = pd.read_csv('./dados/cursos_superiores.csv', sep=\";\", header=0)\n",
    "cursos_tec = pd.read_csv('./dados/cursos_tecnicos.csv', sep=\";\", header=0)\n"
   ],
   "id": "eef2d87d2ab50d81",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agrupar Datasets\n",
   "id": "e8c1b6d47fd60663"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T23:48:20.869526Z",
     "start_time": "2025-01-16T23:48:20.842542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Agrupando os dados por campus \n",
    "grupos_consumo = consumo.groupby('CAMPUS')\n",
    "grupos_feriados = feriados.groupby('CAMPUS')\n",
    "grupos_cursos_sup = cursos_sup.query('Modalidade == \"Educação Presencial\"').groupby('CAMPUS')\n",
    "grupos_cursos_tec = cursos_tec.query('NO_MODALIDADE == \"EDUCAÇÃO PRESENCIAL\"').groupby('CAMPUS')\n",
    "\n",
    "# Criando subdatasets para cada campus \n",
    "subdf_consumo = {campus: dados for campus, dados in grupos_consumo}\n",
    "subdf_feriados = {campus: dados for campus, dados in grupos_feriados}\n",
    "subdf_cursos_sup = {campus: dados for campus, dados in grupos_cursos_sup}\n",
    "subdf_cursos_tec = {campus: dados for campus, dados in grupos_cursos_tec}\n",
    "\n"
   ],
   "id": "17009c1c04179966",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Transformar Dados de Consumo Mensais em Diários",
   "id": "89f0e6dc45361d31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T23:48:23.452808Z",
     "start_time": "2025-01-16T23:48:20.940114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes = []\n",
    "dataframes_ignorados = []\n",
    "for campus, df_consumo in subdf_consumo.items():\n",
    "    dt_min = subdf_consumo[campus][\"DATA INICIO\"].min()\n",
    "    dt_max = subdf_consumo[campus][\"DATA FIM\"].max()\n",
    "\n",
    "    if dt_min.day != 1:\n",
    "        next_month = (dt_min.replace(day=28) + pd.DateOffset(days=4)).replace(day=1)\n",
    "        dt_min = next_month\n",
    "\n",
    "    if dt_max != (dt_max + pd.offsets.MonthEnd(0)):\n",
    "        dt_max = dt_max + pd.offsets.MonthEnd(-1)\n",
    "\n",
    "    datas = pd.date_range(start=dt_min, end=dt_max)\n",
    "    df = pd.DataFrame({'DATA': datas})\n",
    "    df[\"CAMPUS\"] = campus\n",
    "\n",
    "    for index, row in df_consumo.iterrows():\n",
    "        dt_inicio = row['DATA INICIO']\n",
    "        dt_fim = row['DATA FIM']\n",
    "        nr_dias = (dt_fim - dt_inicio).days + 1\n",
    "\n",
    "        mascara = (df['DATA'] >= pd.to_datetime(dt_inicio)) & (df['DATA'] <= pd.to_datetime(dt_fim))\n",
    "        df.loc[mascara, \"CONSUMO\"] = row[\"CONSUMO\"] / nr_dias\n",
    "\n",
    "    if \"PARANAGUÁ\" in campus:\n",
    "        dataframes_ignorados.append(df)\n",
    "    else:\n",
    "        dataframes.append(df)\n",
    "\n",
    "df_merged = pd.merge(dataframes_ignorados[0], dataframes_ignorados[1], on='DATA', how='inner',\n",
    "                     suffixes=('_df1', '_df2'))\n",
    "df_merged[\"CONSUMO\"] = df_merged[\"CONSUMO_df1\"].fillna(0) + df_merged[\"CONSUMO_df2\"].fillna(0)\n",
    "df_merged[\"CAMPUS\"] = \"PARANAGUÁ\"\n",
    "df_merged = df_merged.drop([\"CONSUMO_df1\", \"CONSUMO_df2\", \"CAMPUS_df1\", \"CAMPUS_df2\"], axis=1)\n",
    "dataframes.append(df_merged)\n",
    "\n",
    "df_consumo_normalizado = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df_consumo_normalizado.to_csv(\"./dados/dados_consumo_normalizados.csv\", sep=\";\", decimal=\".\", index=False)\n",
    "\n",
    "grupos_consumo_normalizado = df_consumo_normalizado.groupby('CAMPUS')\n",
    "subdf_consumo_normalizado = {campus: dados for campus, dados in grupos_consumo_normalizado}\n"
   ],
   "id": "6f8cf2d9ae48012e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ajustar Dados Climáticos",
   "id": "54fb0dbd119c50b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T23:48:24.516478Z",
     "start_time": "2025-01-16T23:48:23.559019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_clima = pd.read_csv(\"./dados/clima.csv\", sep=\";\", header=0, decimal=\".\")\n",
    "df_clima_londrina = df_clima.query('CAMPUS == \"LONDRINA\"')\n",
    "\n",
    "df_clima_londrina.loc[df_clima_londrina['CAMPUS'] == \"LONDRINA\", 'CAMPUS'] = \"LONDRINA - NORTE\"\n",
    "df_clima.loc[df_clima['CAMPUS'] == \"LONDRINA\", 'CAMPUS'] = \"LONDRINA - CENTRO\"\n",
    "\n",
    "df_clima = pd.concat([df_clima, df_clima_londrina], ignore_index=True)\n",
    "\n",
    "df_clima[\"DATA\"] = pd.to_datetime(df_clima[\"DATA\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "df_clima.to_csv(\"./dados/dados_climaticos.csv\", sep=\";\", decimal=\".\", index=False)"
   ],
   "id": "d9601a54bc6682ac",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Criar Datasets conforme Calendários Acadêmicos",
   "id": "82c927b3472b68c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T23:50:02.150929Z",
     "start_time": "2025-01-16T23:48:24.592608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for campus, df_feriados in subdf_consumo_normalizado.items():\n",
    "    dt_min = pd.to_datetime(subdf_consumo_normalizado[campus][\"DATA\"]).min()\n",
    "    dt_max = pd.to_datetime(subdf_consumo_normalizado[campus][\"DATA\"]).max()\n",
    "\n",
    "    dt_inicio = datetime.date(year=2010, month=1, day=1)\n",
    "    dt_fim = datetime.date.today()\n",
    "\n",
    "    datas = pd.date_range(start=dt_inicio, end=dt_fim)\n",
    "    df = pd.DataFrame({'DATA': datas})\n",
    "    df[\"CAMPUS\"] = campus\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        data = row['DATA'].date()\n",
    "        dia = data.day\n",
    "        mes = data.month\n",
    "        ano = data.year\n",
    "\n",
    "        rows_data_fixa = feriados.loc[feriados[\"DATA INICIO\"] == f\"{dia}/{mes}\"]\n",
    "        rows_data_flexivel = feriados.loc[feriados[\"DATA INICIO\"] == f\"{dia:02}/{mes:02}/{ano:04}\"]\n",
    "\n",
    "        if not rows_data_fixa.empty:\n",
    "            for _, row_data_fixa in rows_data_fixa.iterrows():\n",
    "                if campus in row_data_fixa[\"CAMPUS\"] or row_data_fixa[\"CAMPUS\"] == \"*\":\n",
    "                    [dia_final_fixo, mes_final_fixo] = str(row_data_fixa[\"DATA FIM\"]).split(\"/\")\n",
    "                    data_final_fixa = datetime.date(ano, int(mes_final_fixo), int(dia_final_fixo))\n",
    "                    mascara = (df['DATA'] >= pd.to_datetime(data)) & (df['DATA'] <= pd.to_datetime(data_final_fixa))\n",
    "                    df.loc[mascara, row_data_fixa[\"MOTIVO\"]] = 1\n",
    "\n",
    "        if not rows_data_flexivel.empty:\n",
    "            for _, row_data_flexivel in rows_data_flexivel.iterrows():\n",
    "                if campus in row_data_flexivel[\"CAMPUS\"] or row_data_flexivel[\"CAMPUS\"] == \"*\":\n",
    "                    [dia_final_flexivel, mes_final_flexivel, ano_final_flexivel] = str(\n",
    "                        row_data_flexivel[\"DATA FIM\"]).split(\"/\")\n",
    "                    data_final_flexivel = datetime.date(int(ano_final_flexivel), int(mes_final_flexivel),\n",
    "                                                        int(dia_final_flexivel))\n",
    "                    mascara = (df['DATA'] >= pd.to_datetime(data)) & (df['DATA'] <= pd.to_datetime(data_final_flexivel))\n",
    "                    df.loc[mascara, row_data_flexivel[\"MOTIVO\"]] = 1\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    df = df.loc[(df['DATA'] >= dt_min) & (df['DATA'] <= dt_max)]\n",
    "    df.to_csv(f\"./dados/calendarios/{campus}.csv\", index=False, sep=\";\", decimal=\".\")\n"
   ],
   "id": "1852980aa8390ff0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Criar Dataset de Dados Temporais",
   "id": "390c839a01e859c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T23:50:06.688605Z",
     "start_time": "2025-01-16T23:50:02.271774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pasta = './dados/calendarios/'\n",
    "\n",
    "# Obter uma lista de todos os arquivos .csv na pasta\n",
    "arquivos_csv = glob.glob(os.path.join(pasta, \"*.csv\"))\n",
    "# Criar uma lista para armazenar os DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterar sobre a lista de arquivos .csv e ler cada um em um DataFrame\n",
    "for arquivo in arquivos_csv:\n",
    "    df = pd.read_csv(arquivo, sep=\";\", header=0)\n",
    "    df['CAMPUS'] = os.path.basename(arquivo.replace(\".csv\", \"\"))\n",
    "    df['DATA'] = pd.to_datetime(df['DATA'])\n",
    "    df['DIA_DA_SEMANA'] = df['DATA'].dt.strftime('%a')\n",
    "    df['MÊS'] = df['DATA'].dt.strftime('%b')\n",
    "    df['ANO'] = df['DATA'].dt.strftime('%Y')\n",
    "    df = pd.get_dummies(df, columns=['DIA_DA_SEMANA', \"MÊS\", \"ANO\"])\n",
    "    df = df.fillna(False)\n",
    "    df[df.drop([\"CAMPUS\", \"DATA\"], axis=1).columns] = df[df.drop([\"CAMPUS\", \"DATA\"], axis=1).columns].astype(int)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame\n",
    "df_completo = pd.concat(dataframes, ignore_index=True)\n",
    "df_completo = df_completo.fillna(0)\n",
    "\n",
    "df_completo.to_csv(\"./dados/dados_temporais.csv\", sep=\";\", decimal=\".\", index=False)\n"
   ],
   "id": "38f32a01bfda035",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Criar Datasets conforme Cursos Superiores (E-MEC)",
   "id": "9f059a4200f52692"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T23:50:07.848346Z",
     "start_time": "2025-01-16T23:50:06.806164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes = []\n",
    "for campus, df_cursos_sup in subdf_cursos_sup.items():\n",
    "    dt_min = pd.to_datetime(subdf_consumo_normalizado[campus][\"DATA\"]).min()\n",
    "    dt_max = pd.to_datetime(subdf_consumo_normalizado[campus][\"DATA\"]).max()\n",
    "\n",
    "    datas = pd.date_range(start=pd.to_datetime(df_cursos_sup[\"Início Funcionamento\"], format='%d/%m/%Y').min(),\n",
    "                          end=datetime.date.today())\n",
    "    df = pd.DataFrame({'DATA': datas})\n",
    "    df[\"CAMPUS\"] = campus\n",
    "    df[\"CURSOS_GRAD_MATUTINO\"] = 0\n",
    "    df[\"CURSOS_GRAD_VESPERTINO\"] = 0\n",
    "    df[\"CURSOS_GRAD_NOTURNO\"] = 0\n",
    "    df[\"CURSOS_POS\"] = 0\n",
    "\n",
    "    for index, row in df_cursos_sup.iterrows():\n",
    "        dt_inicio = pd.to_datetime(row[\"Início Funcionamento\"], format='%d/%m/%Y')\n",
    "        if row[\"Fim Funcionamento\"] is not None and not pd.isnull(row[\"Fim Funcionamento\"]):\n",
    "            dt_fim = pd.to_datetime(row[\"Fim Funcionamento\"], format='%d/%m/%Y')\n",
    "        else:\n",
    "            dt_fim = pd.to_datetime(datetime.date.today())\n",
    "\n",
    "        if row[\"Grau\"] in [\"Bacharelado\", \"Tecnológico\", \"Licenciatura\"]:\n",
    "            if row[\"Quantitativo de Vagas - Integral\"] > 0:\n",
    "                df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)) &\n",
    "                       (df['DATA'] <= pd.to_datetime(dt_fim)), \"CURSOS_GRAD_MATUTINO\"] += 1\n",
    "                df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)) &\n",
    "                       (df['DATA'] <= pd.to_datetime(dt_fim)), \"CURSOS_GRAD_VESPERTINO\"] += 1\n",
    "            else:\n",
    "                if row[\"Quantitativo de Vagas - Matutino\"] > 0:\n",
    "                    df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)) &\n",
    "                           (df['DATA'] <= pd.to_datetime(dt_fim)), \"CURSOS_GRAD_MATUTINO\"] += 1\n",
    "\n",
    "                if row[\"Quantitativo de Vagas - Vespertino\"] > 0:\n",
    "                    df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)) &\n",
    "                           (df['DATA'] <= pd.to_datetime(dt_fim)), \"CURSOS_GRAD_VESPERTINO\"] += 1\n",
    "\n",
    "            if row[\"Quantitativo de Vagas - Noturno\"] > 0:\n",
    "                df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)) &\n",
    "                       (df['DATA'] <= pd.to_datetime(dt_fim)), \"CURSOS_GRAD_NOTURNO\"] += 1\n",
    "\n",
    "        elif row[\"Grau\"] in [\"Especialização\", \"Mestrado\"]:\n",
    "            df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)) &\n",
    "                   (df['DATA'] <= pd.to_datetime(dt_fim)), \"CURSOS_POS\"] += 1\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    df = df.loc[(df['DATA'] >= dt_min) & (df['DATA'] <= dt_max)]\n",
    "    df.to_csv(f\"./dados/cursos_superiores/{campus}.csv\", index=False, sep=\";\", decimal=\".\")\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame\n",
    "df_completo = pd.concat(dataframes, ignore_index=True)\n",
    "df_completo = df_completo.fillna(0)\n",
    "\n",
    "df_completo.to_csv(\"./dados/dados_cursos_superiores.csv\", sep=\";\", decimal=\".\", index=False)\n"
   ],
   "id": "fd5b0245a9347095",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Criar Datasets conforme Cursos Técnicos (SISTEC)",
   "id": "b185eaa3bced20dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T23:50:09.227515Z",
     "start_time": "2025-01-16T23:50:07.928739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes = []\n",
    "for campus, df_cursos_tec in subdf_cursos_tec.items():\n",
    "    dt_min = pd.to_datetime(subdf_consumo_normalizado[campus][\"DATA\"]).min()\n",
    "    dt_max = pd.to_datetime(subdf_consumo_normalizado[campus][\"DATA\"]).max()\n",
    "\n",
    "    datas = pd.date_range(start=pd.to_datetime(df_cursos_tec[\"DATA INICIO\"], format='%d/%m/%Y').min(),\n",
    "                          end=datetime.date.today())\n",
    "    df = pd.DataFrame({'DATA': datas})\n",
    "    df[\"CAMPUS\"] = campus\n",
    "    df[\"CURSOS_TEC_CONCOMITANTE\"] = 0\n",
    "    df[\"CURSOS_TEC_INTEGRADO\"] = 0\n",
    "    df[\"CURSOS_TEC_SUBSEQUENTE\"] = 0\n",
    "\n",
    "    for index, row in df_cursos_tec.iterrows():\n",
    "        dt_inicio = pd.to_datetime(row[\"DATA INICIO\"], format='%d/%m/%Y')\n",
    "        dt_fim = pd.to_datetime(row[\"DATA FIM\"], format='%d/%m/%Y')\n",
    "\n",
    "        if row[\"NO_TIPO_OFERTA\"] == \"CONCOMITANTE\":\n",
    "            df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)) & (\n",
    "                    df['DATA'] <= pd.to_datetime(dt_fim)), \"CURSOS_TEC_CONCOMITANTE\"] += 1\n",
    "        elif row[\"NO_TIPO_OFERTA\"] == \"INTEGRADO\":\n",
    "            df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)) & (\n",
    "                    df['DATA'] <= pd.to_datetime(dt_fim)), \"CURSOS_TEC_INTEGRADO\"] += 1\n",
    "        elif row[\"NO_TIPO_OFERTA\"] == \"SUBSEQUENTE\":\n",
    "            df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)) & (\n",
    "                    df['DATA'] <= pd.to_datetime(dt_fim)), \"CURSOS_TEC_SUBSEQUENTE\"] += 1\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    df = df.loc[(df['DATA'] >= dt_min) & (df['DATA'] <= dt_max)]\n",
    "    df.to_csv(f\"./dados/cursos_tecnicos/{campus}.csv\", index=False, sep=\";\", decimal=\".\")\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame\n",
    "df_completo = pd.concat(dataframes, ignore_index=True)\n",
    "df_completo = df_completo.fillna(0)\n",
    "\n",
    "df_completo.to_csv(\"./dados/dados_cursos_tecnicos.csv\", sep=\";\", decimal=\".\", index=False)\n"
   ],
   "id": "50656627d8195a81",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Mesclar Datasets",
   "id": "3c748f7da1d4b84"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T00:00:45.839835Z",
     "start_time": "2025-01-16T23:59:57.523053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dados_consumo = pd.read_csv(\"./dados/dados_consumo_normalizados.csv\", header=0, sep=\";\", decimal=\".\")\n",
    "dados_climaticos = pd.read_csv(\"./dados/dados_climaticos.csv\", header=0, sep=\";\", decimal=\".\")\n",
    "dados_temporais = pd.read_csv(\"./dados/dados_temporais.csv\", header=0, sep=\";\", decimal=\".\")\n",
    "dados_cursos_tecnicos = pd.read_csv(\"./dados/dados_cursos_tecnicos.csv\", header=0, sep=\";\", decimal=\".\")\n",
    "dados_cursos_superiores = pd.read_csv(\"./dados/dados_cursos_superiores.csv\", header=0, sep=\";\", decimal=\".\")\n",
    "\n",
    "dados_consumo[\"DATA\"] = pd.to_datetime(dados_consumo[\"DATA\"])\n",
    "dados_climaticos[\"DATA\"] = pd.to_datetime(dados_climaticos[\"DATA\"])\n",
    "dados_temporais[\"DATA\"] = pd.to_datetime(dados_temporais[\"DATA\"])\n",
    "dados_cursos_tecnicos[\"DATA\"] = pd.to_datetime(dados_cursos_tecnicos[\"DATA\"])\n",
    "dados_cursos_superiores[\"DATA\"] = pd.to_datetime(dados_cursos_superiores[\"DATA\"])\n",
    "\n",
    "df_merged = (dados_consumo\n",
    "             .merge(dados_climaticos, on=['DATA', \"CAMPUS\"], how='left')\n",
    "             .merge(dados_temporais, on=['DATA', \"CAMPUS\"], how='left')\n",
    "             .merge(dados_cursos_tecnicos, on=['DATA', \"CAMPUS\"], how='left')\n",
    "             .merge(dados_cursos_superiores, on=['DATA', \"CAMPUS\"], how='left'))\n",
    "\n",
    "df_merged[dados_cursos_superiores.columns] = df_merged[dados_cursos_superiores.columns].fillna(0)\n",
    "df_merged[dados_cursos_tecnicos.columns] = df_merged[dados_cursos_tecnicos.columns].fillna(0)\n",
    "\n",
    "for index, row in df_merged[df_merged.isnull().any(axis=1)].iterrows():\n",
    "    mes = pd.to_datetime(row[\"DATA\"]).month\n",
    "    campus = row[\"CAMPUS\"]\n",
    "    for col in df_merged.columns:\n",
    "        if pd.isnull(row[col]) and col in dados_climaticos.columns:\n",
    "            media_mes = df_merged[(df_merged[\"DATA\"].dt.month == mes) &\n",
    "                                  (df_merged[\"CAMPUS\"] == campus)][col].mean()\n",
    "            df_merged.at[index, col] = media_mes\n",
    "        \n",
    "df_merged['TEMP_MIN_MED_MENS'] = df_merged['TEMP_MIN']        \n",
    "df_merged['TEMP_MIN_MIN_MENS'] = df_merged['TEMP_MIN']\n",
    "df_merged['TEMP_MIN_MAX_MENS'] = df_merged['TEMP_MIN']\n",
    "df_merged['TEMP_MIN_ACC_MENS'] = df_merged['TEMP_MIN']\n",
    "df_merged['TEMP_MÉD_MED_MENS'] = df_merged['TEMP_MÉD']\n",
    "df_merged['TEMP_MÉD_MIN_MENS'] = df_merged['TEMP_MÉD']\n",
    "df_merged['TEMP_MÉD_MAX_MENS'] = df_merged['TEMP_MÉD']\n",
    "df_merged['TEMP_MÉD_ACC_MENS'] = df_merged['TEMP_MÉD']\n",
    "df_merged['TEMP_MAX_MED_MENS'] = df_merged['TEMP_MAX']\n",
    "df_merged['TEMP_MAX_MIN_MENS'] = df_merged['TEMP_MAX']\n",
    "df_merged['TEMP_MAX_MAX_MENS'] = df_merged['TEMP_MAX']\n",
    "df_merged['TEMP_MAX_ACC_MENS'] = df_merged['TEMP_MAX']\n",
    "df_merged['PRECIPITAÇÃO_MED_MENS'] = df_merged['PRECIPITAÇÃO']\n",
    "df_merged['PRECIPITAÇÃO_MIN_MENS'] = df_merged['PRECIPITAÇÃO']\n",
    "df_merged['PRECIPITAÇÃO_MAX_MENS'] = df_merged['PRECIPITAÇÃO']\n",
    "df_merged['PRECIPITAÇÃO_ACC_MENS'] = df_merged['PRECIPITAÇÃO']\n",
    "\n",
    "df_merged = df_merged.drop('TEMP_MIN', axis=1)\n",
    "df_merged = df_merged.drop('TEMP_MÉD', axis=1)\n",
    "df_merged = df_merged.drop('TEMP_MAX', axis=1)\n",
    "df_merged = df_merged.drop('PRECIPITAÇÃO', axis=1)\n",
    "\n",
    "df_merged = df_merged.groupby('CAMPUS')\n",
    "\n",
    "dataframes = []\n",
    "for campus, df in df_merged:\n",
    "    df[\"PERIODO\"] = df[\"DATA\"]\n",
    "    df = df.groupby(pd.Grouper(key=\"PERIODO\", freq=\"ME\")).agg({\n",
    "        'CONSUMO': 'sum',\n",
    "        'DATA': \"last\",\n",
    "        'TEMP_MIN_MED_MENS': 'mean',\n",
    "        'TEMP_MIN_MIN_MENS': 'min',\n",
    "        'TEMP_MIN_MAX_MENS': 'max',\n",
    "        'TEMP_MIN_ACC_MENS': 'sum',\n",
    "        'TEMP_MÉD_MED_MENS': 'mean',\n",
    "        'TEMP_MÉD_MIN_MENS': 'min',\n",
    "        'TEMP_MÉD_MAX_MENS': 'max',\n",
    "        'TEMP_MÉD_ACC_MENS': 'sum',\n",
    "        'TEMP_MAX_MED_MENS': 'mean',\n",
    "        'TEMP_MAX_MIN_MENS': 'min',\n",
    "        'TEMP_MAX_MAX_MENS': 'max',\n",
    "        'TEMP_MAX_ACC_MENS': 'sum',\n",
    "        'PRECIPITAÇÃO_MED_MENS': 'mean',\n",
    "        'PRECIPITAÇÃO_MIN_MENS': 'min',\n",
    "        'PRECIPITAÇÃO_MAX_MENS': 'max',\n",
    "        'PRECIPITAÇÃO_ACC_MENS': 'sum',\n",
    "        'FÉRIAS': 'sum',\n",
    "        'FERIADO': 'sum',\n",
    "        'COVID': 'sum',\n",
    "        'GREVE': 'sum',\n",
    "        'DIA_DA_SEMANA_dom': 'sum',\n",
    "        'DIA_DA_SEMANA_seg': 'sum',\n",
    "        'DIA_DA_SEMANA_ter': 'sum',\n",
    "        'DIA_DA_SEMANA_qua': 'sum',\n",
    "        'DIA_DA_SEMANA_qui': 'sum',\n",
    "        'DIA_DA_SEMANA_sex': 'sum',\n",
    "        'DIA_DA_SEMANA_sÃ¡b': 'sum',\n",
    "        'MÊS_jan': 'mean',\n",
    "        'MÊS_fev': 'mean',\n",
    "        'MÊS_mar': 'mean',\n",
    "        'MÊS_abr': 'mean',\n",
    "        'MÊS_mai': 'mean',\n",
    "        'MÊS_jun': 'mean',\n",
    "        'MÊS_jul': 'mean',\n",
    "        'MÊS_ago': 'mean',\n",
    "        'MÊS_set': 'mean',\n",
    "        'MÊS_out': 'mean',\n",
    "        'MÊS_nov': 'mean',\n",
    "        'MÊS_dez': 'mean',\n",
    "        'ANO_2014': 'mean',\n",
    "        'ANO_2015': 'mean',\n",
    "        'ANO_2016': 'mean',\n",
    "        'ANO_2017': 'mean',\n",
    "        'ANO_2018': 'mean',\n",
    "        'ANO_2019': 'mean',\n",
    "        'ANO_2020': 'mean',\n",
    "        'ANO_2021': 'mean',\n",
    "        'ANO_2022': 'mean',\n",
    "        'ANO_2023': 'mean',\n",
    "        'ANO_2024': 'mean',\n",
    "        'CURSOS_TEC_CONCOMITANTE': 'mean',\n",
    "        'CURSOS_TEC_INTEGRADO': 'mean',\n",
    "        'CURSOS_TEC_SUBSEQUENTE': 'mean',\n",
    "        'CURSOS_GRAD_MATUTINO': 'mean',\n",
    "        'CURSOS_GRAD_VESPERTINO': 'mean',\n",
    "        'CURSOS_GRAD_NOTURNO': 'mean',\n",
    "        'CURSOS_POS': 'mean'\n",
    "    })\n",
    "    df[\"CAMPUS\"] = campus\n",
    "    df[\"CONSUMO\"] = round(df[\"CONSUMO\"])\n",
    "    df['TEMP_MIN_MED_MENS'] = round(df['TEMP_MIN_MED_MENS'])\n",
    "    df['TEMP_MIN_MIN_MENS'] = round(df['TEMP_MIN_MIN_MENS'])\n",
    "    df['TEMP_MIN_MAX_MENS'] = round(df['TEMP_MIN_MAX_MENS'])\n",
    "    df['TEMP_MIN_ACC_MENS'] = round(df['TEMP_MIN_ACC_MENS'])\n",
    "    df['TEMP_MÉD_MED_MENS'] = round(df['TEMP_MÉD_MED_MENS'])\n",
    "    df['TEMP_MÉD_MIN_MENS'] = round(df['TEMP_MÉD_MIN_MENS'])\n",
    "    df['TEMP_MÉD_MAX_MENS'] = round(df['TEMP_MÉD_MAX_MENS'])\n",
    "    df['TEMP_MÉD_ACC_MENS'] = round(df['TEMP_MÉD_ACC_MENS'])\n",
    "    df['TEMP_MAX_MED_MENS'] = round(df['TEMP_MAX_MED_MENS'])\n",
    "    df['TEMP_MAX_MIN_MENS'] = round(df['TEMP_MAX_MIN_MENS'])\n",
    "    df['TEMP_MAX_MAX_MENS'] = round(df['TEMP_MAX_MAX_MENS'])\n",
    "    df['TEMP_MAX_ACC_MENS'] = round(df['TEMP_MAX_ACC_MENS'])\n",
    "    df['PRECIPITAÇÃO_MED_MENS'] = round(df['PRECIPITAÇÃO_MED_MENS'])\n",
    "    df['PRECIPITAÇÃO_MIN_MENS'] = round(df['PRECIPITAÇÃO_MIN_MENS'])\n",
    "    df['PRECIPITAÇÃO_MAX_MENS'] = round(df['PRECIPITAÇÃO_MAX_MENS'])\n",
    "    df['PRECIPITAÇÃO_ACC_MENS'] = round(df['PRECIPITAÇÃO_ACC_MENS'])\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame\n",
    "df_completo = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df_completo.to_csv(\"./dados/dados_mesclados.csv\", sep=\";\", decimal=\".\", index=False)\n"
   ],
   "id": "f890b71544644357",
   "outputs": [],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
