{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importações",
   "id": "9cc7a4c844a5230e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-15T23:05:40.537600Z",
     "start_time": "2025-01-15T23:05:40.528514Z"
    }
   },
   "source": [
    "from calendar import month\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import calendar\n",
    "import locale\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "\n",
    "from jinja2 import Undefined\n",
    "\n",
    "locale.setlocale(locale.LC_TIME, 'pt_BR.UTF-8')\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt_BR.UTF-8'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Carregar datasets",
   "id": "72f220b34ac4c7bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T23:05:41.275388Z",
     "start_time": "2025-01-15T23:05:41.201320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "consumo = pd.read_csv('./dados/consumo.csv', sep=\";\", header=0)\n",
    "consumo[\"DATA INICIO\"] = pd.to_datetime(consumo['DATA INICIO'], format='%d/%m/%Y').apply(\n",
    "    lambda x: x.replace(hour=0, minute=0,\n",
    "                        second=0,\n",
    "                        microsecond=0))\n",
    "consumo[\"DATA FIM\"] = pd.to_datetime(consumo['DATA FIM'], format='%d/%m/%Y').apply(\n",
    "    lambda x: x.replace(hour=23, minute=59,\n",
    "                        second=59,\n",
    "                        microsecond=999999))\n",
    "feriados = pd.read_csv('dados/calendarios.csv', sep=\";\", header=0)\n",
    "cursos_sup = pd.read_csv('./dados/cursos_superiores.csv', sep=\";\", header=0)\n",
    "cursos_tec = pd.read_csv('./dados/cursos_tecnicos.csv', sep=\";\", header=0)\n"
   ],
   "id": "eef2d87d2ab50d81",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agrupamento dos Datasets\n",
   "id": "e8c1b6d47fd60663"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T23:05:42.563715Z",
     "start_time": "2025-01-15T23:05:42.544834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Agrupando os dados por campus \n",
    "grupos_consumo = consumo.groupby('CAMPUS')\n",
    "grupos_feriados = feriados.groupby('CAMPUS')\n",
    "grupos_cursos_sup = cursos_sup.query('Modalidade == \"Educação Presencial\"').groupby('CAMPUS')\n",
    "grupos_cursos_tec = cursos_tec.groupby('CAMPUS')\n",
    "\n",
    "# Criando subdatasets para cada campus \n",
    "subdf_consumo = {campus: dados for campus, dados in grupos_consumo}\n",
    "subdf_feriados = {campus: dados for campus, dados in grupos_feriados}\n",
    "subdf_cursos_sup = {campus: dados for campus, dados in grupos_cursos_sup}\n",
    "subdf_cursos_tec = {campus: dados for campus, dados in grupos_cursos_tec}\n",
    "\n"
   ],
   "id": "17009c1c04179966",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Normalização dos meses de Consumo para o mesmo periodo",
   "id": "89f0e6dc45361d31"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T23:48:57.441908Z",
     "start_time": "2025-01-15T23:48:52.082127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframes = []\n",
    "for campus, df_consumo in subdf_consumo.items():\n",
    "    row_ant = None\n",
    "    df = pd.DataFrame(columns=df_consumo.columns)\n",
    "    for index, row in df_consumo.iterrows():\n",
    "        dt_inicio = row['DATA INICIO']\n",
    "        dt_fim = row['DATA FIM']\n",
    "        nova_data_inicio = dt_inicio\n",
    "        nova_data_fim = dt_fim\n",
    "        cons_prop_ant = 0\n",
    "        cons_prop_atual = row[\"CONSUMO\"]\n",
    "        cons_prop_post = 0\n",
    "\n",
    "        # Se este dado começou depois do dia primeiro\n",
    "        if dt_inicio.day > 1:\n",
    "            # Se houver row anterior\n",
    "            if row_ant is not None:\n",
    "                # Se a row anterior terminar depois do inicio desta, lança um erro\n",
    "                if row_ant[\"DATA FIM\"] > dt_inicio:\n",
    "                    raise ValueError(f\"Data final anterior é maior que data de inicio atual\")\n",
    "                dt_inicio_ant = row_ant[\"DATA INICIO\"]\n",
    "                dt_fim_ant = row_ant[\"DATA FIM\"]\n",
    "                num_dias_ant = (dt_fim_ant - dt_inicio_ant).days\n",
    "                num_dias_prop_ant = (dt_fim_ant - dt_inicio.replace(day=1, month=dt_inicio.month)).days\n",
    "                cons_prop_ant = (row_ant[\"CONSUMO\"] / num_dias_ant) * num_dias_prop_ant\n",
    "                nova_data_inicio = nova_data_inicio.replace(day=1, month=dt_inicio.month)\n",
    "            else:\n",
    "                # Se não há row anterior, apenas pula a iteração e muda o valor da row anterior para si\n",
    "                row_ant = row\n",
    "                continue\n",
    "        # Se este dado terminou antes do final do mes inicial\n",
    "        if dt_fim < pd.Timestamp(year=dt_inicio.year, month=dt_inicio.month,\n",
    "                                 day=calendar.monthrange(dt_inicio.year, dt_inicio.month)[1], hour=23, minute=59,\n",
    "                                 second=59, microsecond=999999):\n",
    "            # Se não for o ultimo valor\n",
    "            if index < len(df_consumo)-1:\n",
    "                row_post = df_consumo.iloc[index + 1]\n",
    "                # SE há row seguinte e ela inicia antes do fim desta, lança um erro\n",
    "                if row_post is not None and row_post[\"DATA INICIO\"] < dt_fim:\n",
    "                    raise ValueError(\n",
    "                        f\"Data inicial posterior é menor que data final atual\")\n",
    "                dt_inicio_post = row_post[\"DATA INICIO\"]\n",
    "                dt_final_post = row_post[\"DATA FIM\"]\n",
    "                num_dias_post = (dt_final_post - dt_inicio_post).days\n",
    "                num_dias_prop_post = (\n",
    "                        dt_final_post.replace(day=calendar.monthrange(dt_inicio.year, dt_inicio.month)[1],\n",
    "                                              month=dt_inicio.month) - dt_inicio_post).days\n",
    "                cons_prop_post = row_post[\"CONSUMO\"] / num_dias_post * num_dias_prop_post\n",
    "                nova_data_fim = nova_data_fim.replace(day=calendar.monthrange(dt_inicio.year, dt_inicio.month)[1])\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        if dt_inicio.month != dt_fim.month:\n",
    "            num_dias_atual = (dt_fim - dt_inicio).days\n",
    "            num_dias_prop_atual = (dt_fim.replace(day=calendar.monthrange(dt_fim.year, dt_fim.month)[1]) - dt_inicio).days\n",
    "\n",
    "        novo_df = pd.DataFrame([{\n",
    "            \"DATA INICIO\": nova_data_inicio,\n",
    "            \"DATA FIM\": nova_data_fim,\n",
    "            \"CAMPUS\": campus,\n",
    "            \"CONSUMO\": round(cons_prop_atual + cons_prop_ant + cons_prop_post)\n",
    "        }])\n",
    "        df = pd.concat([df, novo_df], ignore_index=True)\n",
    "\n",
    "        row_ant = row\n",
    "        dataframes.append(df)\n",
    "\n",
    "df_completo = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "df_completo.to_csv(\"./dados/dados_consumo_normalizados.csv\", sep=\";\", decimal=\".\", index=False)\n"
   ],
   "id": "6f8cf2d9ae48012e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_20412\\2393395638.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, novo_df], ignore_index=True)\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Criação dos Datasets conforme Calendários Acadêmicos",
   "id": "82c927b3472b68c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T19:46:08.643016Z",
     "start_time": "2025-01-14T19:45:06.239693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for campus, df_feriados in subdf_feriados.items():\n",
    "    dt_min = pd.to_datetime(subdf_consumo[campus][\"DATA INICIO\"]).min()\n",
    "    dt_max = pd.to_datetime(subdf_consumo[campus][\"DATA FIM\"]).max()\n",
    "\n",
    "    dt_inicio = datetime.date(year=2010, month=1, day=1)\n",
    "    dt_fim = datetime.date.today()\n",
    "\n",
    "    datas = pd.date_range(start=dt_inicio, end=dt_fim)\n",
    "    df = pd.DataFrame({'DATA': datas})\n",
    "    df[\"CAMPUS\"] = campus\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        data = row['DATA'].date()\n",
    "        dia = data.day\n",
    "        mes = data.month\n",
    "        ano = data.year\n",
    "\n",
    "        rows_data_fixa = feriados.loc[feriados[\"DATA INICIO\"] == f\"{dia}/{mes}\"]\n",
    "        rows_data_flexivel = feriados.loc[feriados[\"DATA INICIO\"] == f\"{dia:02}/{mes:02}/{ano:04}\"]\n",
    "\n",
    "        if not rows_data_fixa.empty:\n",
    "            for _, row_data_fixa in rows_data_fixa.iterrows():\n",
    "                if campus in row_data_fixa[\"CAMPUS\"] or row_data_fixa[\"CAMPUS\"] == \"*\":\n",
    "                    [dia_final_fixo, mes_final_fixo] = str(row_data_fixa[\"DATA FIM\"]).split(\"/\")\n",
    "                    data_final_fixa = datetime.date(ano, int(mes_final_fixo), int(dia_final_fixo))\n",
    "                    mascara = (df['DATA'] >= pd.to_datetime(data)) & (df['DATA'] <= pd.to_datetime(data_final_fixa))\n",
    "                    df.loc[mascara, row_data_fixa[\"MOTIVO\"]] = True\n",
    "\n",
    "        if not rows_data_flexivel.empty:\n",
    "            for _, row_data_flexivel in rows_data_flexivel.iterrows():\n",
    "                if campus in row_data_flexivel[\"CAMPUS\"] or row_data_flexivel[\"CAMPUS\"] == \"*\":\n",
    "                    [dia_final_flexivel, mes_final_flexivel, ano_final_flexivel] = str(\n",
    "                        row_data_flexivel[\"DATA FIM\"]).split(\"/\")\n",
    "                    data_final_flexivel = datetime.date(int(ano_final_flexivel), int(mes_final_flexivel),\n",
    "                                                        int(dia_final_flexivel))\n",
    "                    mascara = (df['DATA'] >= pd.to_datetime(data)) & (df['DATA'] <= pd.to_datetime(data_final_flexivel))\n",
    "                    df.loc[mascara, row_data_flexivel[\"MOTIVO\"]] = True\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    df = df.loc[(df['DATA'] >= dt_min) & (df['DATA'] <= dt_max)]\n",
    "    df.to_csv(f\"./dados/calendarios/{campus}.csv\", index=False, sep=\";\", decimal=\".\")\n"
   ],
   "id": "1852980aa8390ff0",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Criação do Dataset de Dados Temporais",
   "id": "390c839a01e859c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T19:54:52.541310Z",
     "start_time": "2025-01-14T19:54:49.258773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pasta = './dados/calendarios/'\n",
    "\n",
    "# Obter uma lista de todos os arquivos .csv na pasta\n",
    "arquivos_csv = glob.glob(os.path.join(pasta, \"*.csv\"))\n",
    "# Criar uma lista para armazenar os DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterar sobre a lista de arquivos .csv e ler cada um em um DataFrame\n",
    "for arquivo in arquivos_csv:\n",
    "    df = pd.read_csv(arquivo, sep=\";\", header=0)\n",
    "    df['CAMPUS'] = os.path.basename(arquivo.replace(\".csv\", \"\"))\n",
    "    df['DATA'] = pd.to_datetime(df['DATA'])\n",
    "    df['DIA_DA_SEMANA'] = df['DATA'].dt.strftime('%a')\n",
    "    df['MÊS'] = df['DATA'].dt.strftime('%b')\n",
    "    df['ANO'] = df['DATA'].dt.strftime('%Y')\n",
    "    df = pd.get_dummies(df, columns=['DIA_DA_SEMANA', \"MÊS\", \"ANO\"])\n",
    "    df = df.fillna(0)\n",
    "    df[df.drop([\"CAMPUS\", \"DATA\"], axis=1).columns] = df[df.drop([\"CAMPUS\", \"DATA\"], axis=1).columns].astype(int)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame\n",
    "df_completo = pd.concat(dataframes, ignore_index=True)\n",
    "df_completo = df_completo.fillna(0)\n",
    "\n",
    "df_completo.to_csv(\"./dados/dados_temporais.csv\", sep=\";\", decimal=\".\", index=False)\n"
   ],
   "id": "38f32a01bfda035",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Criação dos Datasets conforme Cursos Superiores (E-MEC)",
   "id": "9f059a4200f52692"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T17:47:39.099495Z",
     "start_time": "2025-01-15T17:47:37.948698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for campus, df_cursos_sup in subdf_cursos_sup.items():\n",
    "    dt_min = pd.to_datetime(subdf_consumo[campus][\"DATA INICIO\"]).min()\n",
    "    dt_max = pd.to_datetime(subdf_consumo[campus][\"DATA FIM\"]).max()\n",
    "\n",
    "    datas = pd.date_range(start=pd.to_datetime(df_cursos_sup[\"Início Funcionamento\"]).min(), end=datetime.date.today())\n",
    "    df = pd.DataFrame({'DATA': datas})\n",
    "    df[\"CAMPUS\"] = campus\n",
    "    df[\"TURMAS_GRAD_MATUTINO\"] = 0\n",
    "    df[\"TURMAS_GRAD_VESPERTINO\"] = 0\n",
    "    df[\"TURMAS_GRAD_NOTURNO\"] = 0\n",
    "    df[\"TURMAS_POS\"] = 0\n",
    "\n",
    "    for index, row in df_cursos_sup.iterrows():\n",
    "        dt_inicio = pd.to_datetime(row[\"Início Funcionamento\"])\n",
    "        if row[\"Grau\"] in [\"Bacharelado\", \"Tecnológico\", \"Licenciatura\"]:\n",
    "            if row[\"Quantitativo de Vagas - Integral\"] > 0:\n",
    "                n_anos = row[\"Integralização - Turno Noturno (ANOS)\"]\n",
    "                df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)), \"TURMAS_GRAD_MATUTINO\"] += math.ceil(n_anos)\n",
    "                df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)), \"TURMAS_GRAD_VESPERTINO\"] += math.ceil(n_anos)\n",
    "\n",
    "                if campus != \"LONDRINA - NORTE\":\n",
    "                    for i in range(1, math.floor(n_anos)):\n",
    "                        df.loc[(df['DATA'] <= pd.to_datetime(dt_inicio) + pd.DateOffset(\n",
    "                            years=i)), \"TURMAS_GRAD_MATUTINO\"] -= 1\n",
    "                        df.loc[(df['DATA'] <= pd.to_datetime(dt_inicio) + pd.DateOffset(\n",
    "                            years=i)), \"TURMAS_GRAD_VESPERTINO\"] -= 1\n",
    "\n",
    "                    if n_anos % 1 == 5:\n",
    "                        df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio) + pd.DateOffset(years=n_anos) and df[\n",
    "                            'DATA'] <= pd.to_datetime(dt_inicio) + pd.DateOffset(\n",
    "                            years=math.ceil(n_anos))), \"TURMAS_GRAD_MATUTINO\"] -= 1\n",
    "                        df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio) + pd.DateOffset(years=n_anos) and df[\n",
    "                            'DATA'] <= pd.to_datetime(dt_inicio) + pd.DateOffset(\n",
    "                            years=math.ceil(n_anos))), \"TURMAS_GRAD_VESPERTINO\"] -= 1\n",
    "\n",
    "            else:\n",
    "                if row[\"Quantitativo de Vagas - Matutino\"] > 0:\n",
    "                    n_anos = row[\"Integralização - Turno Matutino (ANOS)\"]\n",
    "                    df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)), \"TURMAS_GRAD_MATUTINO\"] += math.ceil(n_anos)\n",
    "                    if campus != \"LONDRINA - NORTE\":\n",
    "                        for i in range(1, math.floor(n_anos)):\n",
    "                            df.loc[(df['DATA'] <= pd.to_datetime(dt_inicio) + pd.DateOffset(\n",
    "                                years=i)), \"TURMAS_GRAD_MATUTINO\"] -= 1\n",
    "\n",
    "                if row[\"Quantitativo de Vagas - Vespertino\"] > 0:\n",
    "                    n_anos = row[\"Integralização - Turno Vespertino (ANOS)\"]\n",
    "                    df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)), \"TURMAS_GRAD_VESPERTINO\"] += math.ceil(n_anos)\n",
    "                    if campus != \"LONDRINA - NORTE\":\n",
    "                        for i in range(1, math.floor(n_anos)):\n",
    "                            df.loc[(df['DATA'] <= pd.to_datetime(dt_inicio) + pd.DateOffset(\n",
    "                                years=i)), \"TURMAS_GRAD_VESPERTINO\"] -= 1\n",
    "\n",
    "            if row[\"Quantitativo de Vagas - Noturno\"] > 0:\n",
    "                n_anos = row[\"Integralização - Turno Noturno (ANOS)\"]\n",
    "                df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)), \"TURMAS_GRAD_NOTURNO\"] += math.ceil(n_anos)\n",
    "                if campus != \"LONDRINA - NORTE\":\n",
    "                    for i in range(1, math.floor(n_anos)):\n",
    "                        df.loc[(df['DATA'] <= pd.to_datetime(dt_inicio) + pd.DateOffset(\n",
    "                            years=i)), \"TURMAS_GRAD_NOTURNO\"] -= 1\n",
    "\n",
    "        elif row[\"Grau\"] == \"Especialização\":\n",
    "            df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)), \"TURMAS_POS\"] += 1\n",
    "        elif row[\"Grau\"] == \"Mestrado\":\n",
    "            # Acrescenta 2 turmas pois o mestrado geralmente tem duração bianual e novas admissões anuais\n",
    "            df.loc[(df['DATA'] >= pd.to_datetime(dt_inicio)), \"TURMAS_POS\"] += 2\n",
    "            # Remove 1 turma pois no primeiro ano geralmente só há 1 turma (mestrados são 2 anos)\n",
    "            df.loc[(df['DATA'] <= pd.to_datetime(dt_inicio) + pd.DateOffset(years=1)), \"TURMAS_POS\"] -= 1\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    df = df.loc[(df['DATA'] >= dt_min) & (df['DATA'] <= dt_max)]\n",
    "    df.to_csv(f\"./dados/cursos/{campus}.csv\", index=False, sep=\";\", decimal=\".\")\n",
    "\n"
   ],
   "id": "fd5b0245a9347095",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LONDRINA'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m campus, df_cursos_sup \u001B[38;5;129;01min\u001B[39;00m subdf_cursos_sup\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m----> 2\u001B[0m     dt_min \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(subdf_consumo[campus][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDATA INICIO\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39mmin()\n\u001B[0;32m      3\u001B[0m     dt_max \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(subdf_consumo[campus][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDATA FIM\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39mmax()\n\u001B[0;32m      5\u001B[0m     datas \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mdate_range(start\u001B[38;5;241m=\u001B[39mpd\u001B[38;5;241m.\u001B[39mto_datetime(df_cursos_sup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInício Funcionamento\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39mmin(), end\u001B[38;5;241m=\u001B[39mdatetime\u001B[38;5;241m.\u001B[39mdate\u001B[38;5;241m.\u001B[39mtoday())\n",
      "\u001B[1;31mKeyError\u001B[0m: 'LONDRINA'"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
